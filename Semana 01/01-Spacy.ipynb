{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_ELGedbTEvV"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/alan-barzilay/NLPortugues/master/imagens/logo_nlportugues.png\"   width=\"150\" align=\"right\">\n",
        "\n",
        "\n",
        "\n",
        "# Lista 1 - spaCy\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8y9-tiGa321"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "387KBr8bTEvY"
      },
      "source": [
        "O [spaCy](\"https://spacy.io\") é uma bilbioteca Python de código fonte [aberto](\"https://github.com/explosion/spaCy\") para Processamento de\n",
        "Linguagem Natural, constantemente atualizada e mantida. Essa biblioteca é capaz de\n",
        "processar diversas línguas, inclusive o português.\n",
        "\n",
        "### Instalação\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8z9R44NUThZb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a19bd02b-3f05-43b3-cdb3-d6fef804434e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (3.8.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (8.3.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy) (2.10.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.1.31)\n",
            "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "%pip install spacy -U"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnieqpc7TEva"
      },
      "source": [
        "Após instalar o pacote spaCy devemos baixar as ferramentas específicas para o português  com o seguinte comando:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "U2xrX5-cqK6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0fb2cf9-8fa5-4dff-9e55-042958636e40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pt-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.8.0/pt_core_news_sm-3.8.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download pt_core_news_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iv8ivfCnTEvd"
      },
      "source": [
        "Uma vez que temos o pacote instalado e os módulos para português baixado,  podemos começar a utilizar  o spaCy, importando o pacote e carregando o módulo para português.\n",
        "\n",
        "**Nota:** Caso seus resultados sejam diferentes dos descritos neste texto isso provavelmente significa que você está utilizando uma versão diferente do spaCy, como essa ferramenta é atualizada com frequência não é incomum encontrar discrepâncias nos resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7pr5NflhTEve"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import pt_core_news_sm\n",
        "spacyPT = pt_core_news_sm.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WUa8_JVmTEvf",
        "outputId": "71af7c1d-2363-4fa4-b852-a45e44e3b16f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.8.4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "spacy.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCgdvPK1TEvg"
      },
      "source": [
        "É importante notar que o spaCy assume que os caracteres estão codificados no formato utf-8.  O primeiro passo portanto é gerar uma entrada nesse formato e submetê-la ao módulo carregado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_o7Q9inqTEvh",
        "outputId": "be9d4fce-0368-4951-bd64-92695f662c41"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Mais vale um asno que me carregue que um cavalo que me derrube."
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "entrada = spacyPT(\"Mais vale um asno que me carregue que um cavalo que me derrube.\")\n",
        "entrada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhoKGbccTEvi"
      },
      "source": [
        "### Tokenização (itemização)\n",
        "\n",
        "A entrada que acabamos de gerar é uma sequência iterável de tokens (itens,  \n",
        "ou instâncias de palavras). Se quisermos verificar qual o texto contido nessa\n",
        "sequência iterável,  usamos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HZFtnbHUTEvj",
        "outputId": "ddb8c526-530f-49a5-c4c2-0b3fe40e756a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mais vale um asno que me carregue que um cavalo que me derrube.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "entrada.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5_1tofrTEvk"
      },
      "source": [
        "Se quisermos dividir a entrada em token,  podemos utilizar o método __split__:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nG2rMfWYTEvm",
        "outputId": "b771701f-7ce1-4456-dd8d-4f891f6c5bb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mais',\n",
              " 'vale',\n",
              " 'um',\n",
              " 'asno',\n",
              " 'que',\n",
              " 'me',\n",
              " 'carregue',\n",
              " 'que',\n",
              " 'um',\n",
              " 'cavalo',\n",
              " 'que',\n",
              " 'me',\n",
              " 'derrube.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "entrada.text.split()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSpMSZrzTEvm"
      },
      "source": [
        "Note que o ponto  final foi absorvido pela palavra;  o mesmo teria acontecido com\n",
        "outros sinais de pontuação a utilizar  o método __split__. Para separar a pontuação\n",
        "das palavras utilizamos a  tokenização implícita realizada pelo comando __in__:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyjtxYEMTEvm",
        "outputId": "77ad7abd-9f74-4152-ec0e-a356a48f9732"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Mais, vale, um, asno, que, me, carregue, que, um, cavalo, que, me, derrube, .]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "[token for token in entrada]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9Fy34xoTEvn"
      },
      "source": [
        "Note que os streams não estão entre aspas,  pois na realidade esta lista contém uma sequência de objetos da classe __Token__.\n",
        "\n",
        "Se o objetivo é obter uma lista de Strings,  podemos proceder da seguinte maneira.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5I-X9vJTEvn",
        "outputId": "891632cb-e959-4236-c016-6a6ca1595895"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mais',\n",
              " 'vale',\n",
              " 'um',\n",
              " 'asno',\n",
              " 'que',\n",
              " 'me',\n",
              " 'carregue',\n",
              " 'que',\n",
              " 'um',\n",
              " 'cavalo',\n",
              " 'que',\n",
              " 'me',\n",
              " 'derrube',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "[token.text for token in entrada]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EC2dnbRTEvp"
      },
      "source": [
        "E para eliminar totalmente a pontuação da lista,  é só restringirr  a sua criação usando __is_punct__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkTxxfstTEvp",
        "outputId": "1ccbfb8e-a1a6-490d-d1a7-bc6121d452e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Mais',\n",
              " 'vale',\n",
              " 'um',\n",
              " 'asno',\n",
              " 'que',\n",
              " 'me',\n",
              " 'carregue',\n",
              " 'que',\n",
              " 'um',\n",
              " 'cavalo',\n",
              " 'que',\n",
              " 'me',\n",
              " 'derrube']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "[token.text for token in entrada if not token.is_punct]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJHmrb02TEvp"
      },
      "source": [
        "O spaCy já vem treinado para realizar etiquetagem morfossintática (PoS tagging),  o que pode ser mostrado da seguinte maneira."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfxFqqCbTEvq",
        "outputId": "7a50ce62-8b30-4824-bd5c-8e6e21fcee5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mais', 'ADV'),\n",
              " ('vale', 'VERB'),\n",
              " ('um', 'DET'),\n",
              " ('asno', 'NOUN'),\n",
              " ('que', 'PRON'),\n",
              " ('me', 'PRON'),\n",
              " ('carregue', 'VERB'),\n",
              " ('que', 'SCONJ'),\n",
              " ('um', 'DET'),\n",
              " ('cavalo', 'NOUN'),\n",
              " ('que', 'PRON'),\n",
              " ('me', 'PRON'),\n",
              " ('derrube', 'PROPN'),\n",
              " ('.', 'PUNCT')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "[(token.text, token.pos_) for token in entrada]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icqdYydXTEvq"
      },
      "source": [
        "A assistência do etiquetador nos permite fazer buscas bastante sofisticadas. Por exemplo podemos buscar os lemas de todos os verbos encontrados  na sentença."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAUS7nCCTEvr",
        "outputId": "429b5cb6-df34-467e-caf3-5055f591550f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['valer', 'carregar']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "[token.lemma_ for token in entrada if token.pos_ == 'VERB']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6Mjy3wMTEvr"
      },
      "source": [
        "Os lemas de verbos conjugados nos fornecem  a sua forma infinitiva."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0bum0sCTEvs"
      },
      "source": [
        "### Reconhecimento de entidades nomeadas\n",
        "\n",
        "A biblioteca já vem treinada com um  mecanismo que permite o reconhecimento de\n",
        "entidades nomeadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFmJt1pYTEvs",
        "outputId": "6a8acdd7-15c9-4add-8840-35a2f5e48f89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(CBF, Comitê de Apelações da FIFA, Neymar, Copa América, Conmebol)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(CBF, 'ORG'),\n",
              " (Comitê de Apelações da FIFA, 'ORG'),\n",
              " (Neymar, 'PER'),\n",
              " (Copa América, 'MISC'),\n",
              " (Conmebol, 'ORG')]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "texto2 = spacyPT(\"A CBF fez um pedido de análise ao Comitê de Apelações da FIFA a fim de diminuir a pena do atacante Neymar, suspenso da Copa América pela Conmebol.\")\n",
        "print(texto2.ents)\n",
        "[(entidade,entidade.label_) for entidade in texto2.ents]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugIP-xrPTEvt"
      },
      "source": [
        "___________________________\n",
        "# <font color='blue'>  Questão 1 </font>\n",
        "\n",
        "Utilizando o spacy, extraia o nome dos personagens presentes no terceiro capitulo da obra \"Mémorias postumas de Brás Cubas\" de Machado de Assis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "NuRJF6YcTEvt",
        "outputId": "0bc0a7c3-9266-405e-e38a-ed3f39316146",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mas, já que falei nos meus dois tios, deixem-me fazer aqui um curto esboço genealógico.        O fundador de minha família foi um certo Damião Cubas, que floresceu na primeira metade do século XVIII. Era tanoeiro de ofício, natural do Rio de Janeiro, onde teria morrido na penúria e na obscuridade, se somente exercesse a tanoaria. Mas não; fez-se lavrador, plantou, colheu, permutou o seu produto por boas e honradas patacas, até que morreu, deixando grosso cabedal a um filho, o licenciado Luís Cubas. Neste rapaz é que verdadeiramente começa a série de meus avós -- dos avós que a minha família sempre confessou -  porque o Damião Cubas era afinal de contas um tanoeiro, e talvez mau tanoeiro, ao passo que o Luís Cubas estudou em Coimbra, primou no Estado, e foi um dos amigos particulares do vice-rei conde da Cunha.        Como este apelido de Cubas lhe cheirasse excessivamente a tanoaria, alegava meu pai, bisneto do Damião, que o dito apelido fora dado a um cavaleiro, herói nas jornadas da Africa, em prêmio da façanha que praticou arrebatando trezentas cubas ao mouros. Meu pai era homem de imaginação; escapou à tanoaria nas asas de um calembour. Era um bom caráter, meu pai, varão digno e leal como poucos. Tinha, é verdade, uns fumos de pacholice; mas quem não é um pouco pachola nesse mundo? Releva notar que ele não recorreu à inventiva senão depois de experimentar a falsificação; primeiramente, entroncou-se na família daquele meu famoso homônimo, o capitão-mor Brás Cubas, que fundou a vila de São Vicente, onde morreu em 1592, e por esse motivo é que me deu o nome de Brás. Opôs-se-lhe, porém, a família do capitão-mor, e foi então que ele imaginou as trezentas cubas mouriscas.        Vivem ainda alguns membros de minha família, minha sobrinha Venância, por exemplo, o lírio-do-vale, que é a flor das damas do seu tempo; vive o pai, o Cotrim, um sujeito que... Mas não antecipemos os sucessos; acabemos de uma vez com o nosso emplasto. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "cap_3_bras_cubas = \"Mas, já que falei nos meus dois tios, deixem-me fazer aqui um curto esboço genealógico.        O fundador de minha família foi um certo Damião Cubas, que floresceu na primeira metade do século XVIII. Era tanoeiro de ofício, natural do Rio de Janeiro, onde teria morrido na penúria e na obscuridade, se somente exercesse a tanoaria. Mas não; fez-se lavrador, plantou, colheu, permutou o seu produto por boas e honradas patacas, até que morreu, deixando grosso cabedal a um filho, o licenciado Luís Cubas. Neste rapaz é que verdadeiramente começa a série de meus avós -- dos avós que a minha família sempre confessou -  porque o Damião Cubas era afinal de contas um tanoeiro, e talvez mau tanoeiro, ao passo que o Luís Cubas estudou em Coimbra, primou no Estado, e foi um dos amigos particulares do vice-rei conde da Cunha.        Como este apelido de Cubas lhe cheirasse excessivamente a tanoaria, alegava meu pai, bisneto do Damião, que o dito apelido fora dado a um cavaleiro, herói nas jornadas da Africa, em prêmio da façanha que praticou arrebatando trezentas cubas ao mouros. Meu pai era homem de imaginação; escapou à tanoaria nas asas de um calembour. Era um bom caráter, meu pai, varão digno e leal como poucos. Tinha, é verdade, uns fumos de pacholice; mas quem não é um pouco pachola nesse mundo? Releva notar que ele não recorreu à inventiva senão depois de experimentar a falsificação; primeiramente, entroncou-se na família daquele meu famoso homônimo, o capitão-mor Brás Cubas, que fundou a vila de São Vicente, onde morreu em 1592, e por esse motivo é que me deu o nome de Brás. Opôs-se-lhe, porém, a família do capitão-mor, e foi então que ele imaginou as trezentas cubas mouriscas.        Vivem ainda alguns membros de minha família, minha sobrinha Venância, por exemplo, o lírio-do-vale, que é a flor das damas do seu tempo; vive o pai, o Cotrim, um sujeito que... Mas não antecipemos os sucessos; acabemos de uma vez com o nosso emplasto. \"\n",
        "cap_3_bras_cubas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "CG6FJniETEvu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f9f22f2-4688-498b-b0df-1ac728fc989e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mas', 'CCONJ'),\n",
              " (',', 'PUNCT'),\n",
              " ('já', 'SCONJ'),\n",
              " ('que', 'SCONJ'),\n",
              " ('falei', 'VERB'),\n",
              " ('nos', 'ADP'),\n",
              " ('meus', 'DET'),\n",
              " ('dois', 'NUM'),\n",
              " ('tios', 'NOUN'),\n",
              " (',', 'PUNCT'),\n",
              " ('deixem-me', 'VERB'),\n",
              " ('fazer', 'VERB'),\n",
              " ('aqui', 'ADV'),\n",
              " ('um', 'DET'),\n",
              " ('curto', 'ADJ'),\n",
              " ('esboço', 'NOUN'),\n",
              " ('genealógico', 'ADJ'),\n",
              " ('.', 'PUNCT'),\n",
              " ('       ', 'SPACE'),\n",
              " ('O', 'DET'),\n",
              " ('fundador', 'NOUN'),\n",
              " ('de', 'ADP'),\n",
              " ('minha', 'DET'),\n",
              " ('família', 'NOUN'),\n",
              " ('foi', 'AUX'),\n",
              " ('um', 'DET'),\n",
              " ('certo', 'ADJ'),\n",
              " ('Damião', 'PROPN'),\n",
              " ('Cubas', 'PROPN'),\n",
              " (',', 'PUNCT'),\n",
              " ('que', 'PRON'),\n",
              " ('floresceu', 'VERB'),\n",
              " ('na', 'ADP'),\n",
              " ('primeira', 'ADJ'),\n",
              " ('metade', 'NOUN'),\n",
              " ('do', 'ADP'),\n",
              " ('século', 'NOUN'),\n",
              " ('XVIII', 'ADJ'),\n",
              " ('.', 'PUNCT'),\n",
              " ('Era', 'AUX'),\n",
              " ('tanoeiro', 'NOUN'),\n",
              " ('de', 'ADP'),\n",
              " ('ofício', 'NOUN'),\n",
              " (',', 'PUNCT'),\n",
              " ('natural', 'ADJ'),\n",
              " ('do', 'ADP'),\n",
              " ('Rio', 'PROPN'),\n",
              " ('de', 'ADP'),\n",
              " ('Janeiro', 'PROPN'),\n",
              " (',', 'PUNCT'),\n",
              " ('onde', 'PRON'),\n",
              " ('teria', 'AUX'),\n",
              " ('morrido', 'VERB'),\n",
              " ('na', 'ADP'),\n",
              " ('penúria', 'NOUN'),\n",
              " ('e', 'CCONJ'),\n",
              " ('na', 'ADP'),\n",
              " ('obscuridade', 'NOUN'),\n",
              " (',', 'PUNCT'),\n",
              " ('se', 'SCONJ'),\n",
              " ('somente', 'ADV'),\n",
              " ('exercesse', 'VERB'),\n",
              " ('a', 'DET'),\n",
              " ('tanoaria', 'NOUN'),\n",
              " ('.', 'PUNCT'),\n",
              " ('Mas', 'CCONJ'),\n",
              " ('não', 'ADV'),\n",
              " (';', 'PUNCT'),\n",
              " ('fez-se', 'VERB'),\n",
              " ('lavrador', 'ADJ'),\n",
              " (',', 'PUNCT'),\n",
              " ('plantou', 'VERB'),\n",
              " (',', 'PUNCT'),\n",
              " ('colheu', 'ADV'),\n",
              " (',', 'PUNCT'),\n",
              " ('permutou', 'VERB'),\n",
              " ('o', 'DET'),\n",
              " ('seu', 'DET'),\n",
              " ('produto', 'NOUN'),\n",
              " ('por', 'ADP'),\n",
              " ('boas', 'NOUN'),\n",
              " ('e', 'CCONJ'),\n",
              " ('honradas', 'NOUN'),\n",
              " ('patacas', 'ADJ'),\n",
              " (',', 'PUNCT'),\n",
              " ('até', 'ADP'),\n",
              " ('que', 'PRON'),\n",
              " ('morreu', 'VERB'),\n",
              " (',', 'PUNCT'),\n",
              " ('deixando', 'VERB'),\n",
              " ('grosso', 'ADV'),\n",
              " ('cabedal', 'ADJ'),\n",
              " ('a', 'ADP'),\n",
              " ('um', 'NUM'),\n",
              " ('filho', 'NOUN'),\n",
              " (',', 'PUNCT'),\n",
              " ('o', 'DET'),\n",
              " ('licenciado', 'NOUN'),\n",
              " ('Luís', 'PROPN'),\n",
              " ('Cubas', 'PROPN'),\n",
              " ('.', 'PUNCT'),\n",
              " ('Neste', 'ADP'),\n",
              " ('rapaz', 'NOUN'),\n",
              " ('é', 'AUX'),\n",
              " ('que', 'SCONJ'),\n",
              " ('verdadeiramente', 'ADV'),\n",
              " ('começa', 'VERB'),\n",
              " ('a', 'DET'),\n",
              " ('série', 'NOUN'),\n",
              " ('de', 'ADP'),\n",
              " ('meus', 'DET'),\n",
              " ('avós', 'VERB'),\n",
              " ('--', 'PUNCT'),\n",
              " ('dos', 'ADP'),\n",
              " ('avós', 'NOUN'),\n",
              " ('que', 'PRON'),\n",
              " ('a', 'DET'),\n",
              " ('minha', 'DET'),\n",
              " ('família', 'NOUN'),\n",
              " ('sempre', 'ADV'),\n",
              " ('confessou', 'VERB'),\n",
              " ('-', 'PUNCT'),\n",
              " (' ', 'SPACE'),\n",
              " ('porque', 'SCONJ'),\n",
              " ('o', 'DET'),\n",
              " ('Damião', 'PROPN'),\n",
              " ('Cubas', 'PROPN'),\n",
              " ('era', 'AUX'),\n",
              " ('afinal', 'NOUN'),\n",
              " ('de', 'ADP'),\n",
              " ('contas', 'NOUN'),\n",
              " ('um', 'DET'),\n",
              " ('tanoeiro', 'NOUN'),\n",
              " (',', 'PUNCT'),\n",
              " ('e', 'CCONJ'),\n",
              " ('talvez', 'ADV'),\n",
              " ('mau', 'ADJ'),\n",
              " ('tanoeiro', 'NOUN'),\n",
              " (',', 'PUNCT'),\n",
              " ('ao', 'ADP'),\n",
              " ('passo', 'NOUN'),\n",
              " ('que', 'SCONJ'),\n",
              " ('o', 'DET'),\n",
              " ('Luís', 'PROPN'),\n",
              " ('Cubas', 'PROPN'),\n",
              " ('estudou', 'VERB'),\n",
              " ('em', 'ADP'),\n",
              " ('Coimbra', 'PROPN'),\n",
              " (',', 'PUNCT'),\n",
              " ('primou', 'VERB'),\n",
              " ('no', 'ADP'),\n",
              " ('Estado', 'NOUN'),\n",
              " (',', 'PUNCT'),\n",
              " ('e', 'CCONJ'),\n",
              " ('foi', 'AUX'),\n",
              " ('um', 'NUM'),\n",
              " ('dos', 'ADP'),\n",
              " ('amigos', 'NOUN'),\n",
              " ('particulares', 'ADJ'),\n",
              " ('do', 'ADP'),\n",
              " ('vice-rei', 'NOUN'),\n",
              " ('conde', 'NOUN'),\n",
              " ('da', 'ADP'),\n",
              " ('Cunha', 'PROPN'),\n",
              " ('.', 'PUNCT'),\n",
              " ('       ', 'SPACE'),\n",
              " ('Como', 'ADP'),\n",
              " ('este', 'DET'),\n",
              " ('apelido', 'NOUN'),\n",
              " ('de', 'ADP'),\n",
              " ('Cubas', 'PROPN'),\n",
              " ('lhe', 'PRON'),\n",
              " ('cheirasse', 'VERB'),\n",
              " ('excessivamente', 'ADV'),\n",
              " ('a', 'DET'),\n",
              " ('tanoaria', 'NOUN'),\n",
              " (',', 'PUNCT'),\n",
              " ('alegava', 'VERB'),\n",
              " ('meu', 'DET'),\n",
              " ('pai', 'NOUN'),\n",
              " (',', 'PUNCT'),\n",
              " ('bisneto', 'NOUN'),\n",
              " ('do', 'ADP'),\n",
              " ('Damião', 'NOUN'),\n",
              " (',', 'PUNCT'),\n",
              " ('que', 'PRON'),\n",
              " ('o', 'DET'),\n",
              " ('dito', 'ADJ'),\n",
              " ('apelido', 'NOUN'),\n",
              " ('fora', 'AUX'),\n",
              " ('dado', 'VERB'),\n",
              " ('a', 'ADP'),\n",
              " ('um', 'DET'),\n",
              " ('cavaleiro', 'NOUN'),\n",
              " (',', 'PUNCT'),\n",
              " ('herói', 'NOUN'),\n",
              " ('nas', 'ADP'),\n",
              " ('jornadas', 'NOUN'),\n",
              " ('da', 'ADP'),\n",
              " ('Africa', 'PROPN'),\n",
              " (',', 'PUNCT'),\n",
              " ('em', 'ADP'),\n",
              " ('prêmio', 'NOUN'),\n",
              " ('da', 'ADP'),\n",
              " ('façanha', 'NOUN'),\n",
              " ('que', 'PRON'),\n",
              " ('praticou', 'VERB'),\n",
              " ('arrebatando', 'VERB'),\n",
              " ('trezentas', 'NOUN'),\n",
              " ('cubas', 'NOUN'),\n",
              " ('ao', 'ADP'),\n",
              " ('mouros', 'NOUN'),\n",
              " ('.', 'PUNCT'),\n",
              " ('Meu', 'DET'),\n",
              " ('pai', 'NOUN'),\n",
              " ('era', 'AUX'),\n",
              " ('homem', 'NOUN'),\n",
              " ('de', 'ADP'),\n",
              " ('imaginação', 'NOUN'),\n",
              " (';', 'PUNCT'),\n",
              " ('escapou', 'VERB'),\n",
              " ('à', 'ADP'),\n",
              " ('tanoaria', 'NOUN'),\n",
              " ('nas', 'ADP'),\n",
              " ('asas', 'NOUN'),\n",
              " ('de', 'ADP'),\n",
              " ('um', 'DET'),\n",
              " ('calembour', 'NOUN'),\n",
              " ('.', 'PUNCT'),\n",
              " ('Era', 'AUX'),\n",
              " ('um', 'DET'),\n",
              " ('bom', 'ADJ'),\n",
              " ('caráter', 'NOUN'),\n",
              " (',', 'PUNCT'),\n",
              " ('meu', 'DET'),\n",
              " ('pai', 'NOUN'),\n",
              " (',', 'PUNCT'),\n",
              " ('varão', 'VERB'),\n",
              " ('digno', 'ADJ'),\n",
              " ('e', 'CCONJ'),\n",
              " ('leal', 'ADJ'),\n",
              " ('como', 'ADP'),\n",
              " ('poucos', 'PRON'),\n",
              " ('.', 'PUNCT'),\n",
              " ('Tinha', 'VERB'),\n",
              " (',', 'PUNCT'),\n",
              " ('é', 'AUX'),\n",
              " ('verdade', 'NOUN'),\n",
              " (',', 'PUNCT'),\n",
              " ('uns', 'DET'),\n",
              " ('fumos', 'VERB'),\n",
              " ('de', 'ADP'),\n",
              " ('pacholice', 'NOUN'),\n",
              " (';', 'PUNCT'),\n",
              " ('mas', 'CCONJ'),\n",
              " ('quem', 'PRON'),\n",
              " ('não', 'ADV'),\n",
              " ('é', 'AUX'),\n",
              " ('um', 'DET'),\n",
              " ('pouco', 'ADV'),\n",
              " ('pachola', 'NOUN'),\n",
              " ('nesse', 'ADP'),\n",
              " ('mundo', 'NOUN'),\n",
              " ('?', 'PUNCT'),\n",
              " ('Releva', 'VERB'),\n",
              " ('notar', 'VERB'),\n",
              " ('que', 'SCONJ'),\n",
              " ('ele', 'PRON'),\n",
              " ('não', 'ADV'),\n",
              " ('recorreu', 'VERB'),\n",
              " ('à', 'ADP'),\n",
              " ('inventiva', 'NOUN'),\n",
              " ('senão', 'ADV'),\n",
              " ('depois', 'ADV'),\n",
              " ('de', 'SCONJ'),\n",
              " ('experimentar', 'VERB'),\n",
              " ('a', 'DET'),\n",
              " ('falsificação', 'NOUN'),\n",
              " (';', 'PUNCT'),\n",
              " ('primeiramente', 'ADV'),\n",
              " (',', 'PUNCT'),\n",
              " ('entroncou-se', 'VERB'),\n",
              " ('na', 'ADP'),\n",
              " ('família', 'NOUN'),\n",
              " ('daquele', 'ADP'),\n",
              " ('meu', 'DET'),\n",
              " ('famoso', 'ADJ'),\n",
              " ('homônimo', 'ADJ'),\n",
              " (',', 'PUNCT'),\n",
              " ('o', 'DET'),\n",
              " ('capitão-mor', 'NOUN'),\n",
              " ('Brás', 'PROPN'),\n",
              " ('Cubas', 'PROPN'),\n",
              " (',', 'PUNCT'),\n",
              " ('que', 'PRON'),\n",
              " ('fundou', 'VERB'),\n",
              " ('a', 'DET'),\n",
              " ('vila', 'PROPN'),\n",
              " ('de', 'ADP'),\n",
              " ('São', 'PROPN'),\n",
              " ('Vicente', 'PROPN'),\n",
              " (',', 'PUNCT'),\n",
              " ('onde', 'PRON'),\n",
              " ('morreu', 'VERB'),\n",
              " ('em', 'ADP'),\n",
              " ('1592', 'NUM'),\n",
              " (',', 'PUNCT'),\n",
              " ('e', 'CCONJ'),\n",
              " ('por', 'ADP'),\n",
              " ('esse', 'DET'),\n",
              " ('motivo', 'NOUN'),\n",
              " ('é', 'VERB'),\n",
              " ('que', 'SCONJ'),\n",
              " ('me', 'PRON'),\n",
              " ('deu', 'VERB'),\n",
              " ('o', 'DET'),\n",
              " ('nome', 'NOUN'),\n",
              " ('de', 'ADP'),\n",
              " ('Brás', 'PROPN'),\n",
              " ('.', 'PUNCT'),\n",
              " ('Opôs-se-lhe', 'PROPN'),\n",
              " (',', 'PUNCT'),\n",
              " ('porém', 'CCONJ'),\n",
              " (',', 'PUNCT'),\n",
              " ('a', 'DET'),\n",
              " ('família', 'NOUN'),\n",
              " ('do', 'ADP'),\n",
              " ('capitão-mor', 'NOUN'),\n",
              " (',', 'PUNCT'),\n",
              " ('e', 'CCONJ'),\n",
              " ('foi', 'AUX'),\n",
              " ('então', 'ADV'),\n",
              " ('que', 'SCONJ'),\n",
              " ('ele', 'PRON'),\n",
              " ('imaginou', 'VERB'),\n",
              " ('as', 'DET'),\n",
              " ('trezentas', 'NOUN'),\n",
              " ('cubas', 'NOUN'),\n",
              " ('mouriscas', 'ADJ'),\n",
              " ('.', 'PUNCT'),\n",
              " ('       ', 'SPACE'),\n",
              " ('Vivem', 'VERB'),\n",
              " ('ainda', 'ADV'),\n",
              " ('alguns', 'DET'),\n",
              " ('membros', 'NOUN'),\n",
              " ('de', 'ADP'),\n",
              " ('minha', 'DET'),\n",
              " ('família', 'NOUN'),\n",
              " (',', 'PUNCT'),\n",
              " ('minha', 'DET'),\n",
              " ('sobrinha', 'VERB'),\n",
              " ('Venância', 'NOUN'),\n",
              " (',', 'PUNCT'),\n",
              " ('por', 'ADP'),\n",
              " ('exemplo', 'NOUN'),\n",
              " (',', 'PUNCT'),\n",
              " ('o', 'DET'),\n",
              " ('lírio-do-vale', 'NOUN'),\n",
              " (',', 'PUNCT'),\n",
              " ('que', 'PRON'),\n",
              " ('é', 'AUX'),\n",
              " ('a', 'DET'),\n",
              " ('flor', 'NOUN'),\n",
              " ('das', 'ADP'),\n",
              " ('damas', 'NOUN'),\n",
              " ('do', 'ADP'),\n",
              " ('seu', 'DET'),\n",
              " ('tempo', 'NOUN'),\n",
              " (';', 'PUNCT'),\n",
              " ('vive', 'VERB'),\n",
              " ('o', 'DET'),\n",
              " ('pai', 'NOUN'),\n",
              " (',', 'PUNCT'),\n",
              " ('o', 'DET'),\n",
              " ('Cotrim', 'PROPN'),\n",
              " (',', 'PUNCT'),\n",
              " ('um', 'DET'),\n",
              " ('sujeito', 'NOUN'),\n",
              " ('que', 'PRON'),\n",
              " ('...', 'PUNCT'),\n",
              " ('Mas', 'CCONJ'),\n",
              " ('não', 'ADV'),\n",
              " ('antecipemos', 'VERB'),\n",
              " ('os', 'DET'),\n",
              " ('sucessos', 'NOUN'),\n",
              " (';', 'PUNCT'),\n",
              " ('acabemos', 'NOUN'),\n",
              " ('de', 'ADP'),\n",
              " ('uma', 'DET'),\n",
              " ('vez', 'NOUN'),\n",
              " ('com', 'ADP'),\n",
              " ('o', 'DET'),\n",
              " ('nosso', 'DET'),\n",
              " ('emplasto', 'NOUN'),\n",
              " ('.', 'PUNCT')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "#Seu código aqui\n",
        "texto_BC = spacyPT(cap_3_bras_cubas)\n",
        "# texto_BC\n",
        "[(token.text, token.pos_) for token in texto_BC]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujmz8q2jTEvv"
      },
      "source": [
        "Quais destas repostas estão corretas?  Quais personagens estão faltando?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AxVwxhJTEvv"
      },
      "source": [
        "**<font color='red'> Sua resposta aqui </font>**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3juZmY0jTEvx"
      },
      "source": [
        "# <font color='blue'>  Questão 2 </font>\n",
        "\n",
        "Extraia todos os pronomes deste capitulo.\n",
        "\n",
        "_____________\n",
        "**<font color='red'> Sua resposta aqui </font>**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SrMsM33ZTEvw"
      },
      "outputs": [],
      "source": [
        "#Seu código aqui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bW_x8XHTEvx"
      },
      "source": [
        "# <font color='blue'>  Questão 3 </font>\n",
        "Utilize os visualizadores para explorar o mapa de dependencias de uma frase a sua escolha deste capitulo.\n",
        "https://spacy.io/usage/visualizers\n",
        "\n",
        "Você pode acessar diretamente uma frase especifica ao utilizar o gerador \"sents\", por exemplo:\n",
        "\n",
        "```python\n",
        "frases = [frase for frase in texto.sents]\n",
        "frases[2]\n",
        "\n",
        "\n",
        "Era tanoeiro de ofício, natural do Rio de Janeiro LOC , onde teria morrido na penúria e na obscuridade, se somente exercesse a tanoaria.\n",
        "```\n",
        "\n",
        "\n",
        "_______________\n",
        "\n",
        "\n",
        "**<font color='red'> Sua resposta aqui </font>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqUiCknrTEvy"
      },
      "outputs": [],
      "source": [
        "from spacy import displacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AWMKGioTEvy"
      },
      "outputs": [],
      "source": [
        "#Seu código aqui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmCGp6yNTEvz"
      },
      "source": [
        "# Fontes\n",
        "Tanto o capitulo utilizado nesta aula quanto a obra completa fazem parte do dominio publico e podem ser encontrados em http://www.dominiopublico.gov.br/download/texto/bv000215.pdf"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Copy of 01-Spacy.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv_tutorial",
      "language": "python",
      "name": ".venv_tutorial"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}